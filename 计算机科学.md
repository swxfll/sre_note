# 常见线程模型

## 1 进程和线程

进程

*   PCB
*   数据段
*   程序段

线程

*   TCB
*   数据段
*   程序段

**进程是资源分配的基本单位, 线程是可执行的基本单位, 是可被调度的基本单位**
**线程不可以自己独立拥有资源, 线程的执行必须依赖于所属进程中的资源,进程中必须至少应该有一个线程**

以现代标准而言，一个标准PC的操作系统应该提供以下的功能：

*   进程管理（Processing management）
    *   在进程之下尚有线程的问题，但是大部分的操作系统并不会处理线程所遭遇的问题，通常操作系统仅止于提供一组API让用户自行操作或透过虚拟机的管理机制控制线程之间的交互。
*   内存管理（Memory management）
    *   大部分的现代电脑存储器架构都是层次结构式的，最快且数量最少的**寄存器**为首，然后是缓存、存储器以及最慢的磁盘存储设备。
*   文件系统（File system）
*   网络通信（Networking）
*   安全机制（Security）
*   用户界面（User interface）
*   驱动程序（Device drivers）

操作系统之本意原为提供简单的工作排序能力，后为辅助更新更复杂的硬件设施而渐渐演化。

总而言之，操作系统的历史就是一部解决电脑系统需求与问题的历史。

狭义上的操作系统, 通常指的是运行在裸硬件(裸金属)上的,用于抽象并管理硬件资源的软件.维基百科对此进行了定义:操作系统(Operating Systemc, 缩写: OS)是一组主管并控制计算机操作、运用和运行硬件、软件资源和提供公共服务来组织用户交互的相互关联的系统软件程序,同时也是计算机系统的核心与基石.操作系统需要处理如管理与配置内存、决定系统资源供需的优先次序、控制输入与输出装置、操作网络与管理文件系统等基本事务.操作系统也提供一个让使用者与系统互动的操作页面.

⼴义上的操作系统，Kubernetes也算是操作系统的⼀员。操作系统的设计与实现是⼯业软件（AutoCAD、Maya、Matlab、MySQL）的基础和内核。通常我们认为，操作系统指的是内核，⽽类似于Bash、Finder 等软件属于操作系统上提供的软件。操作系统内核需要接触到各式各样的硬件设备，⽽内核开发者不可能涵盖到所有的硬件，尤其是在这个硬件层出不穷的时代。因此需要将内核与硬件设备进⾏解耦，这就是驱动程序的由来。内核提供⼀系列的协议，驱动程序需要遵守这些协议，然后转化为指定硬件的操作。

通常这个"操作页面"分为图形化操作页面和终端操作页面.常见的图形化操作系统有macOS和Windows,Linux和UNIX存在众多的发行版,有的用于开发板,通常使用串口作为操作页面;有的用于工作站,通常厂商会开发一个图形化的桌面;有的用于服务器,通常使用网络连接作为操作页面.

在内核上会有大量的软件,如果所有的软件均直接运行在内核上,那么内核将变得不安全.现代的内核通常提供两种模式:**内核模式**和**用户模式**.软件和一部分驱动工作在用户模式中, 一些必要的驱动直接工作在内核模式.内核的设计从一开始的单任务发展到多任务,例如Linux的内核提供了`task_struct`这个数据结构描述任务.但是创造内核任务是昂贵的,因为内核需要维护**上下文**并且负责任务的调度.而现代软件通常是多个任务同时执行的,因此用户模式下的任务变得受欢迎.从此,进程变为一个划分资源的单位,例如一个Bash登录环境后就会创建一个进程,并为此分配内存和处理器资源.

> 上下文
> 上下文在不同的地方表示不同的含义
> 看，一篇文章，给你摘录一段，没前没后，你读不懂，因为有语境，就是语言环境存在，一段话说了什么，要通过上下文(文章的上下文)来推断。
> 子程序之于程序，进程之于操作系统，甚至app的一屏之于app，都是一个道理。
> 程序执行了部分到达子程序，子程序要获得结果，要用到程序之前的一些结果(包括但不限于外部变量值，外部对象等等)；app点击一个按钮进入一个新的界面，也要保存你是在哪个屏幕跳过来的等等信息，以便你点击返回的时候能正确跳回，如果不存肯定就无法正确跳回了。看这些都是上下文的典型例子，理解成环境就可以，
> context是environment的snapshot.
> [什么是上下文](https://juejin.cn/post/6844903954816434190)
> [编程中什么是「Context(上下文)」？](https://www.zhihu.com/question/26387327/answer/32618592)

由于需要运行很多的任务,那么在**Linux2.4版本**之前,内核没有提供线程的概念.人们通常写一个线程库来模拟线程.让多个线程在一个进程资源空间中运行,所以说线程是任务(调度单位、代码块)的最小单位.由于各家针对的线程的实现风格迥异,而且也只是模拟,多个线程针对内核还是一个进程,**并不能运行到多核心上**.想要实现真正的线程,读内核的改动是非常大的,RedHat和IBM分别给出了方案:

*   RedHat 提供了 NTPL(Native POSIX Thread Library)项目
*   IBM 提供了NGTP(Next Generation POSIX Threads)项目

后来由于各种原因,IBM放弃了该项目,至此,RedHat NPTL 项目成为 Linux 默认的线程库.各种编程语言也提供了很多任务管理的库,Linux上常见的有C/C++ -- Glibc.Glibc是GNU发布的C/C++运行时库,几乎任何库都依赖于Glibc,比如JVM的线程通过Native方式创建任务.人们通过NPTL调用创建线程的函数创造线程,这些线程都是内核级别的线程.与进程一样,内核级别的线程通常也是昂贵的.面对高并发和大量的客户端应用频繁的创建和销毁内核线程使得内核不堪重负.为了**尽最大力度去复用内核线程**,人们发明了用户线程.那么,那就产生了一个问题:**用户线程使用怎么样的方式映射到内核线程?**

在现实世界中,人们提供了三种方式:

*   1:1(内核级线程模型)
*   1\:N(用户级线程模型)
*   M\:N(混合式线程模型)

**注意:内核线程通常称为KSE(Kernel Scheduling Entity, 内核调度实体).这些KSE参与CPU时间片的瓜分,多个KSE在一个CPU核心上运行就是并发,多个KSE在多个CPU核心上运行就是并行**

### 1.1 用户线程映射到内核线程的方式

#### 1:1(内核级线程模型)

![image](https://assetsasda.oss-cn-guangzhou.aliyuncs.com/devops/%E5%86%85%E6%A0%B8%E7%BA%A7%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.png)
将用户线程以1:1的方式映射到内核线程上.用户线程阻塞之后不会影响其他线程的执行,而且可以让多线程程序拥有更好的表现.许多操作系统限制了内核线程的数量,所以间接导致用户线程受损.大部分编程语言的线程库如\:Linux的`pthread`、java的`java.lang.Thread`和C++的`std::thread`都是包装了操作系统的线程.其调度完全是操作系统线程调度器来做.

由于操作系统内核直接创建线程、销毁线程,并且还需要维护线程的上下文信息,因此资源成本大幅度上升.内核级线程模型在多处理器架构上,内核能够并行执行同一个进程中的多个线程,如果发生阻塞直接切换同一个进程中的其他线程执行.该模型的另一个缺点在于所有阻塞线程的操作都是以系统调用的形式进行的.

#### N:1(用户级线程模型)

![image](https://assetsasda.oss-cn-guangzhou.aliyuncs.com/devops/%E7%94%A8%E6%88%B7%E7%BA%A7%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.png)

将用户线程以 N:1 的方式映射到内核线程上.语言运行时通常会实现一个线程调度器,线程之间的切换由语言运行时实现.内核感受不到线程的切换和实现,内核的所有调度都是基于用户进程的. Python的gevent协程库实现采用该模型.该模型对系统资源较小,整体上来说较为轻量级.

**最大的缺点在于不是真正意义上的并发**.某个用户线程由于I/O阻塞或者系统调用阻塞会导致整个用户进程阻塞,因为用户进程中的线程没有接收CPU中断的能力,属于自调度

在用户级线程模型下,多处理器架构也只是用户进程关联到一个CPU,很多协程库将一些阻塞的操作封装成非阻塞的,在阻塞代码段让出CPU时间片并通过某种手段通知其他用户线程运行,避免内核调度器由于内核线程阻塞做**上下文**切换,解决整个用户进程阻塞问题.

该模型解决了某些操作系统不支持线程的情况,用户线程的状态级切换和上下文托管都在用户进程中实现,调度算法不受操作系统限制.用户线程模型能够利用较多的堆栈空间,并且不需要系统调用和系统内核上下文切换,更不需要刷新内存高速缓存,使得用户线程的调度速度很快.[用户级线程线程的存在意义是什么?](https://www.zhihu.com/question/307787570/answer/592442800)


#### N:M 混合式线程模型
![image](https://assetsasda.oss-cn-guangzhou.aliyuncs.com/devops/%E6%B7%B7%E5%90%88%E5%BC%8F%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B.png)

将用户线程以N:M的方式映射到内核线程上
语言运行时调度器和内核都参与工作

进程和线程的元数据维护在栈空间,进程栈空间执行时是确定的,与编译链接无关.进程栈空间的大小是随机的,并且要比线程栈空间高出2倍.线程栈空间也是确定的,可以使用`ulimit -a`查看,使用`ulimit -s`修改.一般默认情况下,`线程栈在进程的堆中分配`,每个线程拥有独立的栈空间,为了避免线程之间的栈空间踩踏,线程栈之间还会以小块 Guard Size 用来隔离保护各自的栈空间(4K大小的保护页, 防止栈溢出),一旦另一个线程踏入到这个隔离区,就会引发段错误.

# 2 SMP NUMA MPP

目前, 商用服务器处理架构有三种: SMP(Symmetric Multi-Processor, 对称多处理器结构)、NUMA(Non-Uniform Memory Access, 非一致存储访问结构)和MPP(Massive Parallel Processing, 海量并行处理结构)

为什么需要多处理器架构?主要在于三个优点:
1. 增加吞吐量:通过增加处理器数量,以期望在更短的时间内完成工作.采用N个处理器的加速并不等于N,而是接近于N.当多个处理器协同完成同一个任务时,会存在一定的额外开销.
2. 规模经济:多处理器协同的价格远低于相同负载的单元处理器系统,多处理器系统可以共享大量的外设、大容量的存储存储和电源.如果多个程序同时操作一个数据集,那么将这些数据放在同一个磁盘并让多处理器共享出力,这要比拷贝副本更加节省.
3. 增加可靠性:如果将功能分布在多个处理器上,那么单处理器的故障不会使得整个系统停止运行.单处理器系统崩溃对于数据中心是致命的.

## 2.1 SMP(Symmetric Multi-Processor, 对称多处理器结构)
SMP是相对于⾮对称多处理器技术应⽤最⼴泛的并⾏计算技术。在 SMP 中，所有处理器的地位都是平等的，通过总线连接到同⼀个共享的物理
内存，硬件系统中的所有资源都是共享的。SMP 应⽤⼴泛的主要原因在于⼤部分的
⼿机、笔记本都在使⽤该架构，并且⼀些较为⽼旧的服务器也使⽤这种架构。对于
SMP 架构的服务器来说，每⼀个共享环节都并发的访问硬件资源，这就导致当
CPU 数量增加后，资源的抢占不断增加。
实验证明：SMP 架构的服务器 CPU 利⽤率最好的情况是 2~4 个 CPU。

![image](https://assetsasda.oss-cn-guangzhou.aliyuncs.com/devops/SMP_-_Symmetric_Multiprocessor_System.svg.png)


## 2.2 NUMA(Non-Uniform Memory Access, 非一致存储访问结构)
NUMA 的提出在于 SMP 扩展能⼒的限制。不过 NUMA 架构解决横向扩展能⼒的同时带来了**访问延迟**。NUMA 将资源划分，提供了 Node（节点）的概念。
NUMA 使⽤ Node 的概念将硬件资源进⾏分割，每个 Node 都有独有的处理器核⼼、内存和 I/O 资源。这样做的依据就是访问本地资源的速度远远⾼于其他资源，但是同样的问题在于多个 Node 之间资源交互⾮常慢，当 CPU 增多的时候，性能提升幅度并不是很⾼。
利⽤ NUMA 技术，可以较好地解决原来 SMP 系统的扩展问题，在⼀个物理服务器内可以⽀持上百个 CPU 。
![image](https://assetsasda.oss-cn-guangzhou.aliyuncs.com/devops/numa1.png)
![image](https://assetsasda.oss-cn-guangzhou.aliyuncs.com/devops/numa2.png)

## 2.3 MPP(Massive Parallel Processing, 海量并行处理结构)
⼤规模并⾏处理系统，这样的系统是由许多松耦合的处理单元组成的，要注意的是这⾥指的是处理单元⽽不是处理器。每个单元内的CPU都有⾃⼰私有的资源，如总线，内存，硬盘等。在每个单元内都有操作系统和管理数据库的实例复本。这种结构最⼤的特点在于不共享资源。

由多个SMP服务器通过⼀定的节点互联⽹络进⾏连接（信息交互的过程⼀般称为数据重分配），协同⼯作，完成相同的任务，从⽤户的⻆度来看是⼀个服务器系统。

理论上其扩展⽆限制，⽬前的技术可实现 512 个节点互联，数千个 CPU 。在MPP 系统中，每个 SMP 节点也可以运⾏⾃⼰的操作系统、数据库等。MPP 服务器需要⼀种复杂的机制来调度和平衡各个节点的负载和并⾏处理过程。

⽬前⼀些基于 MPP 技术的服务器往往通过系统级软件 ( 如数据库 ) 来屏蔽这种复杂性。


## 2.4 三种多处理器架构的应⽤场景
- MPP系统不共享资源，因此对它⽽⾔，资源⽐SMP要多，当需要处理的事务达到⼀定规模时，MPP的效率要⽐SMP好。由于MPP系统因为要在不同处理单元之间传送信息，在通信时间少的时候，那MPP系统可以充分发挥资源的优势，达到⾼效率。也就是说：操作相互之间没有什么关系，处理单元之间需要进⾏的通信⽐较少，那采⽤MPP系统就要好。因此，MPP系统在决策⽀持和数据挖掘⽅⾯显示了优势。

- MPP系统因为要在不同处理单元之间传送信息，所以它的效率要⽐SMP要差⼀点。在通讯时间多的时候，那MPP系统可以充分发挥资源的优势。因此当前使⽤的OLTP程序中，⽤户访问⼀个中⼼数据库，如果采⽤SMP系统结构，它的效率要⽐采⽤MPP结构要快得多。

- NUMA架构来看，它可以在⼀个物理服务器内集成许多CPU，使系统具有较⾼的事务处理能⼒，由于远地内存访问时延远⻓于本地内存访问，因此需要尽量减少不同CPU模块之间的数据交互。显然，NUMA架构更适⽤于OLTP事务处理环境，当⽤于数据仓库环境时，由于⼤量复杂的数据处理必然导致⼤量的数据交互，将使CPU的利⽤率⼤⼤降低。

# 3 ARM 处理器、新型的内存、⽹卡、硬盘与 FPGA 设备
## [ARM 架构简介](https://www.arm.com/en/architecture/cpu)

# 4 缓存⼀致性协议 MESI
CPU 通常在内存存取数据，由于 CPU 的运算核⼼通常⽐内存速度⾼出⼏个数量级，那么 CPU 通常会在核⼼旁边设置⾼速缓存。

局部性原理: 在CPU访问存储设备时，⽆论是存取数据抑或存取指令，都趋于聚集在⼀⽚连续的区域中，这就被称为局部性原理。

- 时间局部性: 如果⼀个信息项正在被访问，那么在近期它很可能还会被再次访问。
- 空间局部性: 如果⼀个存储器的位置被引⽤，那么将来他附近的位置也会被引⽤。

这些结论都是⼈们从⼤量的⽣产实践观察总结出来的。

当 CPU 中设计了⾼速缓存，那么 CPU 执⾏指令的流程为:程序以及数据加载到主内存，然后指令和数据加载到 CPU 的⾼速缓存；CPU 执⾏指令，把结果写到⾼速缓存中，然后⾼速缓存将数据落实到内存。由于CPU的运算速度超越了1级缓存的数据I\O能⼒，CPU⼚商⼜引⼊了多级的缓存结构。


**MESI 协议缓存状态**

| 状态 | 描述 | 监听任务 |
| --- | --- | --- |
| M 修改 (Modified | 该缓存行有效,数据被修改了,和内存中的数据不一致,数据只存在于本缓存中 | 缓存行必须时刻监听所有试图读该缓存行相对与主存的操作,这种操作必须在缓存将该缓存行写回主存并将状态变成S(共享)状态之前被执行 |
| E 独享、互斥(Exclusive) | 该缓存行有效,数据和内存中的数据一致,数据只存在于本缓存中 | 缓存行必须监听其它缓存读主存中该缓存行的操作,一旦有这种操作,该缓存行需要变成S(共享)状态 |
| S 共享(Shared) | 该缓存行有效,数据和内存中的数据一致,数据存在于很多缓存中 | 缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求,并将该缓存变成无效(Invalid) |
| I 无效(Invalid) | 该缓存行无效 | 无 |


| 触发事件 | 描述 |
| --- | --- |
| local Read | 本地缓存读取本地数据 |
| local Write | 本地缓写入取本地数据 |
| Remote Read | 其它缓存读取本地数据 |
| Remote Write | 其它缓存写入本地数据 |

![image](https://assetsasda.oss-cn-guangzhou.aliyuncs.com/devops/mesi%E7%BC%93%E5%AD%98.png)

对于M和E状态⽽⾔总是精确的，他们在和该缓存⾏的真正状态是⼀致的，⽽S状态可能是⾮⼀致的。如果⼀个缓存将处于S状态的缓存⾏作废了，⽽另⼀个缓存实际上可能已经独享了该缓存⾏，但是该缓存却不会将该缓存⾏升迁为E状态，这是因为其它缓存不会⼴播他们作废掉该缓存⾏的通知，同样由于缓存并没有保存该缓存⾏的拷⻉的数量，因此（即使有这种通知）也没有办法确定⾃⼰是否已经独享了该缓存⾏。
从上⾯的意义看来E状态是⼀种投机性的优化：如果⼀个CPU想修改⼀个处于S状态的缓存
⾏，总线事务需要将所有该缓存⾏的拷⻉变成I状态，⽽修改E状态的缓存不需要使⽤总线事
务。














































